{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands On Day 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In class lab WAP : USE CRISP-DM approach to analyse and prepare data for classification modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem statement\n",
    "The data provided is from a Personal Loans Campaign executed by a bank.Customers were targeted with an offer of Personal Loans at 10% interest rate. The target variable is whether the customer responded to the campaign and availed the personal loan.\n",
    "Using the dataset perform the following:\n",
    "\n",
    "\n",
    "Using the dataset, perform \n",
    "1. Check out for null values in the dataset.\n",
    "2. Describe the data and check all the unique paramenters in the columns & range of important numerical variables\n",
    "3. Calculate the % of responders vs non-responders - comment on whether the data is balanced or imbalanced\n",
    "4. Analyse how the  % of responders vary by - Gender, Occupation\n",
    "5. Build a demographic profile of the banks's customers describing their age range, gender distribution and occupation\n",
    "6. Analyse how the following factors vary with the target variable:\n",
    "   * Age\n",
    "   * Balance\n",
    "   * LEN_OF_REL\n",
    "7. Come up with other variables that you think might impact a response from a customer and analyse how they change with the target variable.\n",
    "8. What model performance measures will you use to evaluate the model - explain the rationale\n",
    "9. Perform logistic regression to predict if a customer will respond to the campaign and identify the variables that influence the target variable\n",
    "10. Interpret the logistic regression model summary using Odds ratio\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dict = pd.read_csv('PL_XSELL2.csv')\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the useful libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the csv file\n",
    "df = pd.read_csv('PL_XSELL2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the number of rows and columns\n",
    "print ('DataFrame Shape', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the top 3 rows of data\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get info about datatype of each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert relevant columns to categorical variable\n",
    "df['TARGET'] = df['TARGET'].astype('category')\n",
    "df['FLG_HAS_CC'] = df['FLG_HAS_CC'].astype('category')\n",
    "df['FLG_HAS_ANY_CHGS'] = df['FLG_HAS_ANY_CHGS'].astype('category')  \n",
    "df['FLG_HAS_NOMINEE'] = df['FLG_HAS_NOMINEE'].astype('category')\n",
    "df['FLG_HAS_OLD_LOAN'] = df['FLG_HAS_OLD_LOAN'].astype('category')\n",
    "\n",
    "#Get info about datatype of each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain summary of columns with numerical data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase #3 Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing some data cleaning, validation, and sanity checks before performing any analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop redundant columns\n",
    "df = df.drop(['CUST_ID'], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Checking for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort customers from oldest to newest\n",
    "df.sort_values(by='LEN_OF_REL', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers and Distributions\n",
    "\n",
    "To get a good understanding of the questions that are being asked, it may be necessary to remove projects with very small and large project goal's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (18,6)\n",
    "\n",
    "def histogram_plot(dataset, column, x_label, title):\n",
    "    '''\n",
    "    Plots histogram of input feature\n",
    "    \n",
    "    INPUT\n",
    "    dataset = dataset with feature that is to be plotted\n",
    "    column = feature of dataset to be plotted\n",
    "    x_label = Label title of the x axis\n",
    "    title = Plot figure title\n",
    "    \n",
    "    OUTPUT\n",
    "    Distribution plot\n",
    "    '''\n",
    "    plt.figure(figsize=figsize);\n",
    "    plt.hist(data = dataset, x = column, bins = 20);\n",
    "    plt.xlabel(x_label);\n",
    "    plt.grid(False)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##distribution of account balance\n",
    "\n",
    "\n",
    "histogram_plot(df, 'BALANCE', 'Account Balance INR', 'Customer distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is an extremely left skewed distribtuion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Project Length Distribution\n",
    "\n",
    "figsize = (18,6)\n",
    "\n",
    "\n",
    "histogram_plot(df, 'LEN_OF_REL', 'Length of Relationship in months', 'Account Length Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis - Finding Answers\n",
    "\n",
    "### Calculate the % of responders vs non-responders - comment on whether the data is balanced or imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Unique Categories of Target: ',df.TARGET.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### % of positive response = # of projects with TARGET=1 / total rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of positive & negative responses in the Y variable\n",
    "df.TARGET.value_counts()/(len(df))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse how the % of responders vary by - Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_perc = round(pd.crosstab(df.TARGET, df.GENDER, normalize='columns'),2)\n",
    "gender_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response is higher for Men compared to Women"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse how the  % of responders vary by - Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_perc = round(pd.crosstab(df.TARGET, df.OCCUPATION, normalize='columns'),2)\n",
    "occ_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response is highest for Self employed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a demographic profile of the banks's customers describing their age range, gender distribution and occupation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.AGE.describe())\n",
    "print(df.OCCUPATION.value_counts())\n",
    "print(df.GENDER.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse how the following factors vary with the target variable:\n",
    "   * Age\n",
    "   * Balance\n",
    "   * LEN_OF_REL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AGE vs TARGET\n",
    "sns.boxplot(x=\"AGE\", y=\"TARGET\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BALANCE vs TARGET\n",
    "sns.boxplot(x=\"BALANCE\", y=\"TARGET\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LEN OF REL vs TARGET\n",
    "sns.boxplot(x=\"LEN_OF_REL\", y=\"TARGET\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCR vs target\n",
    "### SCR vs TARGET\n",
    "sns.boxplot(x=\"SCR\", y=\"TARGET\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"NO_OF_L_CR_TXNS\", y=\"TARGET\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"NO_OF_L_DR_TXNS\", y=\"TARGET\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ability to hold money in the account \n",
    "sns.boxplot(x=\"HOLDING_PERIOD\", y=\"TARGET\", data=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_perc = round(pd.crosstab(df.TARGET, df.ACC_TYPE, normalize='columns'),2)\n",
    "acc_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_perc = round(pd.crosstab(df.TARGET, df.FLG_HAS_CC, normalize='columns'),2)\n",
    "flag_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag1_perc = round(pd.crosstab(df.TARGET, df.FLG_HAS_ANY_CHGS, normalize='columns'),2)\n",
    "flag1_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform logistic regression to predict if a customer will respond to the campaign and identify the variables that influence the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop variables with near zero variance\n",
    "threshold = 0.01\n",
    "\n",
    "model_df = model_df.drop(model_df.std()[model_df.std() < threshold].index.values, axis=1)\n",
    "print(model_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find highly correlated columns\n",
    "#Create a subset of numerical variables\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "newdf = model_df.select_dtypes(include=numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get top absolute correlations\n",
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Top Absolute Correlations\")\n",
    "print(get_top_abs_correlations(newdf, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete certain columns before model building\n",
    "model_df = model_df.drop(['AMT_L_DR',\"AVG_AMT_PER_ATM_TXN\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X and Y variables\n",
    "X  =  model_df.drop(['TARGET'], axis=1)\n",
    "y  =  model_df[['TARGET']]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert categorical vriables to dummy variables\n",
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression using stats model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "logit = sm.Logit(y_train, sm.add_constant(X_train))\n",
    "lg = logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary of logistic regression\n",
    "lg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Odds Ratio\n",
    "#Calculate Odds Ratio\n",
    "lgcoef = pd.DataFrame(lg.params, columns=['coef'])\n",
    "lgcoef.loc[:, \"Odds_ratio\"] = np.exp(lgcoef.coef)\n",
    "lgcoef['pval']=lg.pvalues\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "lgcoef\n",
    "lgcoef.to_csv('logit_handson.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Odds Ratio\n",
    "lgcoef = pd.DataFrame(lg.params, columns=['coef'])\n",
    "lgcoef.loc[:, \"Odds_ratio\"] = np.exp(lgcoef.coef)\n",
    "lgcoef['probability'] = lgcoef['Odds_ratio']/(1+lgcoef['Odds_ratio'])\n",
    "lgcoef['pval']=lg.pvalues\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "lgcoef\n",
    "\n",
    "lgcoef = lgcoef.sort_values(by=\"Odds_ratio\", ascending=False)\n",
    "pval_filter = lgcoef['pval']<=0.05\n",
    "lgcoef[pval_filter]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
