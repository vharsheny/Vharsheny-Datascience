{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE BAYES CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automobile accidents\n",
    "\n",
    "The file Accidents.csv contains information on 42,183 actual automobile accidents in 2001 in the United States that involved one of three levels of injury: NO INJURY, INJURY, or FATALITY. For each accident, additional information is recorded, such as day of week, weather conditions, and road type. <br>\n",
    "A firm might be interested in developing a system for quickly classifying the severity of an\n",
    "accident based on initial reports and associated data in the system (some of which rely\n",
    "on GPS-assisted reporting). <br>\n",
    "\n",
    "## Objective\n",
    "* predict whether the accident will be a serious one based on the provided data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the model using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix,auc,roc_auc_score\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Pima Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('accidents.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NO OF Rows and Columns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check to if DATA is in which Form Numeric or Categorical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert relevant variables to categorical variables\n",
    "df['RushHour'] = df['RushHour'].astype('category')\n",
    "df['WRK_ZONE'] = df['WRK_ZONE'].astype('category')\n",
    "df['WKDY'] = df['WKDY'].astype('category')\n",
    "df['INT_HWY'] = df['INT_HWY'].astype('category')\n",
    "df['LGTCON_day'] = df['LGTCON_day'].astype('category')\n",
    "df['LEVEL'] = df['LEVEL'].astype('category')\n",
    "df['SUR_COND_dry'] = df['SUR_COND_dry'].astype('category')\n",
    "df['TRAF_two_way'] = df['TRAF_two_way'].astype('category')\n",
    "df['WEATHER_adverse'] = df['WEATHER_adverse'].astype('category')\n",
    "df['MAX_SEV'] = df['MAX_SEV'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if any Null values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NO Null Values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MAX_SEV'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping Based On Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Group numerical variables by mean\n",
    "df.groupby(\"MAX_SEV\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.hist(figsize=(10,8), grid=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOXPLOT on the data (Outlier Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind= 'box',subplots=True, layout=(3,3), sharex=False, sharey=False, figsize=(10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create dataframes for X and Y variables\n",
    "x = df.drop([\"MAX_SEV\"], axis=1)\n",
    "y = df[['MAX_SEV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert x to dummy variables\n",
    "x=pd.get_dummies(x, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Invoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_G = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm_G = confusion_matrix(y_test, y_pred_G)\n",
    "cm_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "optimal_alpha = 1\n",
    "NB_optimal = BernoulliNB(alpha=optimal_alpha)\n",
    "\n",
    "# fitting the model\n",
    "NB_optimal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_B = NB_optimal.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_optimal.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(NB_optimal.feature_count_[1], x.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn_class2 = sorted(zip(NB_optimal.feature_count_[1], x.columns),reverse=True)[:12]\n",
    "topn_class2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn_class1 = sorted(zip(NB_optimal.feature_count_[0], x.columns),reverse=True)[:12]\n",
    "topn_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_G = confusion_matrix(y_test, y_pred_G)\n",
    "cm_B = confusion_matrix(y_test, y_pred_B)\n",
    "\n",
    "print(cm_G)\n",
    "print(cm_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred_G))\n",
    "print(accuracy_score(y_test, y_pred_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = NB_optimal.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_test, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_classes(y_scores, t):\n",
    "    \"\"\"\n",
    "    This function adjusts class predictions based on the prediction threshold (t).\n",
    "    Will only work for binary classification problems.\n",
    "    \"\"\"\n",
    "    return [1 if y >= t else 0 for y in y_scores]\n",
    "\n",
    "def precision_recall_threshold(p, r, thresholds, t=0.5):\n",
    "    \"\"\"\n",
    "    plots the precision recall curve and shows the current value for each\n",
    "    by identifying the classifier's threshold (t).\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate new class predictions based on the adjusted_classes\n",
    "    # function above and view the resulting confusion matrix.\n",
    "    y_pred_adj = adjusted_classes(y_scores, t)\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred_adj),\n",
    "                       columns=['pred_neg', 'pred_pos'], \n",
    "                       index=['neg', 'pos']))\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_threshold(p, r, thresholds, 0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    \"\"\"\n",
    "    Modified from:\n",
    "    Hands-On Machine learning with Scikit-Learn\n",
    "    and TensorFlow; p.89\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(\"Precision and Recall Scores as a function of the decision threshold\")\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xlabel(\"Decision Threshold\")\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same p, r, thresholds that were previously calculated\n",
    "plot_precision_recall_vs_threshold(p, r, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the predicted probabilities for class 1\n",
    "y_pred_prob = NB_optimal.predict_proba(X_test)[:, 1]\n",
    "y_pred_prob[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of predicted probabilities\n",
    "\n",
    "# 8 bins\n",
    "plt.hist(y_pred_prob, bins=20)\n",
    "\n",
    "# x-axis limit from 0 to 1\n",
    "plt.xlim(0,1)\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted probability of diabetes')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing the cut off value for prediction\n",
    "pred_proba_df = pd.DataFrame(classifier.predict_proba(X_test))\n",
    "threshold_list = [0.3,0.4,0.41, 0.45, 0.5,0.55, 0.6]\n",
    "for i in threshold_list:\n",
    "    print ('\\n******** For i = {} ******'.format(i))\n",
    "    y_test_pred = pred_proba_df.applymap(lambda x: 1 if x>i else 0)\n",
    "    test_accuracy = metrics.accuracy_score(y_test.values.reshape(y_test.values.size,1),\n",
    "                                           y_test_pred.iloc[:,1].values.reshape(y_test_pred.iloc[:,1].values.size,1))\n",
    "    print('Our testing accuracy is {:.2f}'.format(test_accuracy))\n",
    "\n",
    "    print(confusion_matrix(y_test.values.reshape(y_test.values.size,1),\n",
    "                           y_test_pred.iloc[:,1].values.reshape(y_test_pred.iloc[:,1].values.size,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
